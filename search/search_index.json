{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CM for MLPerf Inference","text":""},{"location":"benchmarks/","title":"MLPerf Inference Benchmarks","text":""},{"location":"benchmarks/image_classification/","title":"Image Classification","text":""},{"location":"benchmarks/image_classification/resnet50/","title":"Image Classification using ResNet50","text":""},{"location":"benchmarks/image_classification/resnet50/#dataset","title":"Dataset","text":"<p>The benchmark implementation run command will automatically download the validation and calibration datasets and do the necessary preprocessing. In case you want to download only the datasets, you can use the below commands.</p> ValidationCalibration <p>ResNet50 validation run uses the Imagenet 2012 validation dataset consisting of 50,000 images.</p> <p>ResNet50 calibration dataset consist of 500 images selected from the Imagenet 2012 validation dataset. There are 2 alternative options for the calibration dataset.</p>"},{"location":"benchmarks/image_classification/resnet50/#get-validation-dataset","title":"Get Validation Dataset","text":"<pre><code>cm run script --tags=get,dataset,imagenet,validation -j\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#get-calibration-dataset-using-option-1","title":"Get Calibration Dataset Using Option 1","text":"<pre><code>cm run script --tags=get,dataset,imagenet,calibration,_mlperf.option1 -j\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#get-calibration-dataset-using-option-2","title":"Get Calibration Dataset Using Option 2","text":"<pre><code>cm run script --tags=get,dataset,imagenet,calibration,_mlperf.option2 -j\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#model","title":"Model","text":"<p>The benchmark implementation run command will automatically download the required model and do the necessary conversions. In case you want to only download the official model, you can use the below commands.</p> <p>Get the Official MLPerf ResNet50 Model</p> TensorflowOnnx"},{"location":"benchmarks/image_classification/resnet50/#tensorflow","title":"Tensorflow","text":"<pre><code>cm run script --tags=get,ml-model,resnet50,_tensorflow -j\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#onnx","title":"Onnx","text":"<pre><code>cm run script --tags=get,ml-model,resnet50,_onnx -j\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#benchmark-implementations","title":"Benchmark Implementations","text":"MLCommons-PythonNvidiaIntelQualcommMLCommon-C++"},{"location":"benchmarks/image_classification/resnet50/#mlperf-reference-implementation-in-python","title":"MLPerf Reference Implementation in Python","text":"edgedatacenter"},{"location":"benchmarks/image_classification/resnet50/#edge-category","title":"Edge category","text":"<p>In the edge category, resnet50 has Offline, SingleStream, Multistream scenarios and all the scenarios are mandatory for a closed division submission.</p> OnnxruntimeTensorflowDeepsparse"},{"location":"benchmarks/image_classification/resnet50/#onnxruntime-framework","title":"Onnxruntime framework","text":"CPUCUDAROCm"},{"location":"benchmarks/image_classification/resnet50/#cpu-device","title":"CPU device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device","title":"CUDA device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_1","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_1","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_1","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_1","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#rocm-device","title":"ROCm device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_2","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_2","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_2","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_2","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#tensorflow-framework","title":"Tensorflow framework","text":"CPUCUDAROCm"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_1","title":"CPU device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_3","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_3","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_3","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_3","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_1","title":"CUDA device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_4","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_4","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_4","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_4","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#rocm-device_1","title":"ROCm device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_5","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_5","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_5","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_5","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#deepsparse-framework","title":"Deepsparse framework","text":"CPU"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_2","title":"CPU device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_6","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_6","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_6","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_6","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#datacenter-category","title":"Datacenter category","text":"<p>In the datacenter category, resnet50 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p> OnnxruntimeTensorflowDeepsparse"},{"location":"benchmarks/image_classification/resnet50/#onnxruntime-framework_1","title":"Onnxruntime framework","text":"CPUCUDAROCm"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_3","title":"CPU device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_7","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_7","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_2","title":"CUDA device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_8","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_1","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_8","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#rocm-device_2","title":"ROCm device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_9","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_2","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_9","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=onnxruntime \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#tensorflow-framework_1","title":"Tensorflow framework","text":"CPUCUDAROCm"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_4","title":"CPU device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_10","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_3","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_10","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_3","title":"CUDA device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_11","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_4","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_11","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#rocm-device_3","title":"ROCm device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_12","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_5","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_12","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=tensorflow \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=rocm  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#deepsparse-framework_1","title":"Deepsparse framework","text":"CPU"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_5","title":"CPU device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_13","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_6","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_13","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=reference \\\n   --framework=deepsparse \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#nvidia-mlperf-implementation","title":"Nvidia MLPerf Implementation","text":"edgedatacenter"},{"location":"benchmarks/image_classification/resnet50/#edge-category_1","title":"Edge category","text":"<p>In the edge category, resnet50 has Offline, SingleStream, Multistream scenarios and all the scenarios are mandatory for a closed division submission.</p> TensorRT"},{"location":"benchmarks/image_classification/resnet50/#tensorrt-framework","title":"TensorRT framework","text":"CUDA"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_4","title":"CUDA device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_14","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_7","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_7","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_14","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#datacenter-category_1","title":"Datacenter category","text":"<p>In the datacenter category, resnet50 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p> TensorRT"},{"location":"benchmarks/image_classification/resnet50/#tensorrt-framework_1","title":"TensorRT framework","text":"CUDA"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_5","title":"CUDA device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_15","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_7","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_15","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=nvidia \\\n   --framework=tensorrt \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#intel-mlperf-implementation","title":"Intel MLPerf Implementation","text":"edgedatacenter"},{"location":"benchmarks/image_classification/resnet50/#edge-category_2","title":"Edge category","text":"<p>In the edge category, resnet50 has Offline, SingleStream, Multistream scenarios and all the scenarios are mandatory for a closed division submission.</p> Pytorch"},{"location":"benchmarks/image_classification/resnet50/#pytorch-framework","title":"Pytorch framework","text":"CPU"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_6","title":"CPU device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_16","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_8","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_8","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_16","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#datacenter-category_2","title":"Datacenter category","text":"<p>In the datacenter category, resnet50 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p> Pytorch"},{"location":"benchmarks/image_classification/resnet50/#pytorch-framework_1","title":"Pytorch framework","text":"CPU"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_7","title":"CPU device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_17","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_8","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_17","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=intel \\\n   --framework=pytorch \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#qualcomm-ai100-mlperf-implementation","title":"Qualcomm AI100 MLPerf Implementation","text":"edgedatacenter"},{"location":"benchmarks/image_classification/resnet50/#edge-category_3","title":"Edge category","text":"<p>In the edge category, resnet50 has Offline, SingleStream, Multistream scenarios and all the scenarios are mandatory for a closed division submission.</p> Glow"},{"location":"benchmarks/image_classification/resnet50/#glow-framework","title":"Glow framework","text":"QAIC"},{"location":"benchmarks/image_classification/resnet50/#qaic-device","title":"QAIC device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_18","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_9","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_9","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_18","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#datacenter-category_3","title":"Datacenter category","text":"<p>In the datacenter category, resnet50 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p> Glow"},{"location":"benchmarks/image_classification/resnet50/#glow-framework_1","title":"Glow framework","text":"QAIC"},{"location":"benchmarks/image_classification/resnet50/#qaic-device_1","title":"QAIC device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_19","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_9","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_19","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=qualcomm \\\n   --framework=glow \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=qaic  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#mlperf-modular-implementation-in-c","title":"MLPerf Modular Implementation in C++","text":"edgedatacenter"},{"location":"benchmarks/image_classification/resnet50/#edge-category_4","title":"Edge category","text":"<p>In the edge category, resnet50 has Offline, SingleStream, Multistream scenarios and all the scenarios are mandatory for a closed division submission.</p> Onnxruntime"},{"location":"benchmarks/image_classification/resnet50/#onnxruntime-framework_2","title":"Onnxruntime framework","text":"CPUCUDA"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_8","title":"CPU device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_20","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_10","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_10","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_20","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_6","title":"CUDA device","text":"OfflineSingleStreamMultistreamAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_21","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#singlestream_11","title":"# SingleStream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=SingleStream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#multistream_11","title":"# Multistream","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge \\\n   --scenario=Multistream \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_21","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=edge  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#datacenter-category_4","title":"Datacenter category","text":"<p>In the datacenter category, resnet50 has Offline, Server scenarios and all the scenarios are mandatory for a closed division submission.</p> Onnxruntime"},{"location":"benchmarks/image_classification/resnet50/#onnxruntime-framework_3","title":"Onnxruntime framework","text":"CPUCUDA"},{"location":"benchmarks/image_classification/resnet50/#cpu-device_9","title":"CPU device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_22","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_10","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_22","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cpu  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#cuda-device_7","title":"CUDA device","text":"OfflineServerAll Scenarios"},{"location":"benchmarks/image_classification/resnet50/#offline_23","title":"# Offline","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Offline \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#server_11","title":"# Server","text":"<pre><code>cm run script --tags=run-mlperf,inference \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter \\\n   --scenario=Server \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"benchmarks/image_classification/resnet50/#all-scenarios_23","title":"# All Scenarios","text":"<pre><code>cm run script --tags=run-mlperf,inference,_all-scenarios \\\n   --model=resnet50 \\\n   --implementation=cpp \\\n   --framework=onnxruntime \\\n   --category=datacenter  \\\n   --execution-mode=valid \\\n   --device=cuda  \\\n   --docker\n</code></pre>"},{"location":"changelog/","title":"What's New, What's Coming","text":""},{"location":"changelog/changelog/","title":"Release Notes","text":""},{"location":"demos/","title":"Demos","text":""},{"location":"install/","title":"Installation","text":""},{"location":"usage/","title":"Using CM for MLPerf Inference","text":""}]}